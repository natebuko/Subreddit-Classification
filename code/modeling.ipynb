{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "---\n",
    "\n",
    "***Data Science Problem:***\n",
    "> Using comments and submissions from the `r/history` and `r/Futurology` subreddits, can we build a model that can tell the difference between a conversation about the future and a conversation about the past?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Contents:\n",
    "- [Imports](#imports)\n",
    "- [Modeling Prep](#prep)\n",
    "    - [Base Model](#base-model)\n",
    "    - [Logistic Regression](#log-reg-prep)\n",
    "    - [Naive Bayes](#naive-bayes-prep)\n",
    "    - [k-Nearest Neighbors](#knn)\n",
    "    - [Random Forest](#random-forest)\n",
    "    - [Support Vector Machine](#svm)\n",
    "- [Results](#results)\n",
    "    - [Logistic Regression](#log-reg-results)\n",
    "    - [Naive Bayes](#naive-bayes-results)\n",
    "    - [k-Nearest Neighbors](#knn-results)\n",
    "    - [Random Forest](#random-forest-results)\n",
    "    - [Support Vector Machine](#svm-results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "\n",
    "## Imports\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifierf\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "reddit_data = pd.read_csv('./data/reddit_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>Hello, /u/Woofislove! Thank you for your parti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user1688</td>\n",
       "      <td>Taking away freedom after a crisis. This is tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>natemb123</td>\n",
       "      <td>Yep but that would lead to a decrease in oil d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lIllIlIIlll</td>\n",
       "      <td>no i wouldn't be surprised lol i have a gradua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tyler56721</td>\n",
       "      <td>You must live a very lavish lifestyle.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author                                               text  subreddit\n",
       "0  AutoModerator  Hello, /u/Woofislove! Thank you for your parti...          1\n",
       "1       user1688  Taking away freedom after a crisis. This is tr...          1\n",
       "2      natemb123  Yep but that would lead to a decrease in oil d...          1\n",
       "3    lIllIlIIlll  no i wouldn't be surprised lol i have a gradua...          1\n",
       "4     tyler56721             You must live a very lavish lifestyle.          1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prep'></a>\n",
    "\n",
    "## Modeling Prep\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='base-model'></a>\n",
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.502429\n",
       "1    0.497571\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Base Model accuracy is 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set X and y values\n",
    "X = reddit_data['text']\n",
    "y = reddit_data['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=6,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='log-reg-prep'></a>\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_model(X_train, X_test, y_train, y_test, vectorizer):\n",
    "    \n",
    "    # Count Vectorized model\n",
    "    if vectorizer == 'cvec':\n",
    "        \n",
    "        # instantiate pipeline\n",
    "        pipe = Pipeline([\n",
    "            ('cvec', CountVectorizer()),\n",
    "            ('logreg', LogisticRegression(solver='lbfgs', max_iter=10_000))\n",
    "        ])\n",
    "        \n",
    "        # set pipeline parameters\n",
    "        pipe_params = {\n",
    "            'cvec__max_features': [None, 5_000, 10_000],\n",
    "            'cvec__stop_words': [None, 'english'],\n",
    "            'cvec__ngram_range': [(1, 1), (1, 2)]\n",
    "        }\n",
    "    \n",
    "    # Tfidf-Vectorized model\n",
    "    if vectorizer == 'tvec':\n",
    "        \n",
    "        # instantiate pipeline\n",
    "        pipe = Pipeline([\n",
    "            ('tvec', TfidfVectorizer()),\n",
    "            ('logreg', LogisticRegression(solver='lbfgs', max_iter=10_000))\n",
    "        ])\n",
    "        \n",
    "        # set pipeline parameters\n",
    "        pipe_params = {\n",
    "            'tvec__max_features': [None, 5_000, 10_000],\n",
    "            'tvec__stop_words': [None, 'english'],\n",
    "            'tvec__ngram_range': [(1, 1), (1, 2)]\n",
    "        }\n",
    "\n",
    "    \n",
    "    # instantiate gridsearch\n",
    "    gs = GridSearchCV(pipe,\n",
    "                      pipe_params,\n",
    "                      cv=5)\n",
    "    \n",
    "    # fit model\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    # print out accuracy scores and best model parameters\n",
    "    print(f\"{vectorizer} logistic regression model:\")\n",
    "    print(\"===============================\")\n",
    "    print(f\"Best Score: {gs.best_score_}\")\n",
    "    print(f\"Best Parameters: {gs.best_params_}\\n\")\n",
    "    print(f\"Test Score: {gs.score(X_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='naive-bayes-prep'></a>\n",
    "\n",
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes\n",
    "def mnb_model(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # instantiate pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('cvec', CountVectorizer()),\n",
    "        ('mnb', MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "    # set gridsearch parameters\n",
    "    pipe_params = {\n",
    "        'cvec__max_features': [None, 5_000, 10_000],\n",
    "        'cvec__stop_words': [None, 'english'],\n",
    "        'cvec__ngram_range': [(1, 1), (1, 2)]\n",
    "    }\n",
    "    \n",
    "    # instantiate gridsearch\n",
    "    gs = GridSearchCV(pipe,\n",
    "                      pipe_params,\n",
    "                      cv=5)\n",
    "    \n",
    "    # fit model\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    # print out accuracy scores and best model parameters\n",
    "    print(\"multinomial naive bayes model:\")\n",
    "    print(\"==============================\")\n",
    "    print(f\"Best Score: {gs.best_score_}\")\n",
    "    print(f\"Best Parameters: {gs.best_params_}\\n\")\n",
    "    print(f\"Test Score: {gs.score(X_test, y_test)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "def gnb_model(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # instantiate estimator\n",
    "    gnb = GaussianNB()\n",
    "    \n",
    "    # instantiate vectorizer\n",
    "    tvec = TfidfVectorizer()\n",
    "    \n",
    "    # fit and transform features\n",
    "    tvec_train_data_features = tvec.fit_transform(X_train)\n",
    "    tvec_test_data_features = tvec.transform(X_test)\n",
    "    \n",
    "    # fit model\n",
    "    gnb.fit(tvec_train_data_features.toarray(), y_train)\n",
    "    \n",
    "    # print out accuracy scores\n",
    "    print(\"gaussian naive bayes model:\")\n",
    "    print(\"===========================\")\n",
    "    print(f\"Train Score: {gnb.score(tvec_train_data_features.toarray(), y_train)}\")\n",
    "    print(f\"Test Score: {gnb.score(tvec_test_data_features.toarray(), y_test)}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='knn-prep'></a>\n",
    "\n",
    "### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_cvec_model(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "#     ss = StandardScaler()\n",
    "\n",
    "    # instantiate vectorizer\n",
    "    cvec = CountVectorizer()\n",
    "    \n",
    "    # fit and transform features\n",
    "    cvec_train_data_features = cvec.fit_transform(X_train)\n",
    "    cvec_test_data_features = cvec.transform(X_test)\n",
    "    \n",
    "#     cvec_train_data_features_scaled = ss.fit_transform(cvec_train_data_features)\n",
    "#     cvec_test_data_features_scaled = ss.transform(vec_test_data_features)   \n",
    "    \n",
    "    # set gridsearch parameters\n",
    "    params = {\n",
    "        'n_neighbors': [5, 15, 25]\n",
    "    }\n",
    "    \n",
    "    # instantiate gridsearch\n",
    "    gs = GridSearchCV(KNeighborsClassifier(),\n",
    "                      params,\n",
    "                      cv=5)\n",
    "    \n",
    "    # fit model\n",
    "    gs.fit(cvec_train_data_features, y_train)\n",
    "    \n",
    "    # print out accuracy scores and best model parameters\n",
    "    print(\"k-nearest neighbors cvec model:\")\n",
    "    print(\"===============================\")\n",
    "    print(f\"Best Score: {gs.best_score_}\")\n",
    "    print(f\"Best Parameters: {gs.best_params_}\\n\")\n",
    "    print(f\"Test Score: {gs.score(cvec_test_data_features, y_test)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_tvec_model(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # instantiate vectorizer\n",
    "    tvec = TfidfVectorizer()\n",
    "    \n",
    "    # fit and transform features\n",
    "    tvec_train_data_features = tvec.fit_transform(X_train)\n",
    "    tvec_test_data_features = tvec.transform(X_test)\n",
    "    \n",
    "    # set gridsearch parameters\n",
    "    params = {\n",
    "        'n_neighbors': [5, 15, 25]\n",
    "    }\n",
    "    \n",
    "    # instantiate gridsearch\n",
    "    gs = GridSearchCV(KNeighborsClassifier(),\n",
    "                      params,\n",
    "                      cv=5)\n",
    "    \n",
    "    # fit model\n",
    "    gs.fit(tvec_train_data_features, y_train)\n",
    "    \n",
    "    # print out accuracy scores and best model parameters\n",
    "    print(\"k-nearest neighbors tvec model:\")\n",
    "    print(\"===============================\")\n",
    "    print(f\"Best Score: {gs.best_score_}\")\n",
    "    print(f\"Best Parameters: {gs.best_params_}\\n\")\n",
    "    print(f\"Test Score: {gs.score(tvec_test_data_features, y_test)}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='random-forest'></a>\n",
    "\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_cvec_model(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # instantiate estimator\n",
    "    rf = RandomForestClassifier(random_state=6)\n",
    "    \n",
    "    # instantiate vectorizer\n",
    "    cvec = CountVectorizer()\n",
    "    \n",
    "    # fit and transform features\n",
    "    cvec_train_data_features = cvec.fit_transform(X_train)\n",
    "    cvec_test_data_features = cvec.transform(X_test)\n",
    "    \n",
    "    # fit model\n",
    "    cvec.fit(cvec_train_data_features, y_train)\n",
    "    \n",
    "    # print out accuracy scores\n",
    "    print(\"random forest cvec model:\")\n",
    "    print(\"=========================\")\n",
    "    print(f\"Train Score: {cvec.score(cvec_train_data_features, y_train)}\")  \n",
    "    print(f\"Test Score: {cvec.score(cvec_test_data_features, y_test)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_tvec_model(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=6)\n",
    "    tvec = TfidfVectorizer()\n",
    "\n",
    "    # fit and transform features\n",
    "    tvec_train_data_features = tvec.fit_transform(X_train)\n",
    "    tvec_test_data_features = tvec.transform(X_test)\n",
    "    \n",
    "    # fit model\n",
    "    tvec.fit(tvec_train_data_features, y_train)\n",
    "    \n",
    "    # print out accuracy scores\n",
    "    print(\"random forest tvec model:\")\n",
    "    print(\"=========================\")\n",
    "    print(f\"Train Score: {tvec.score(tvec_train_data_features, y_train)}\")  \n",
    "    print(f\"Test Score: {tvec.score(tvec_test_data_features, y_test)}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='svm'></a>\n",
    "\n",
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_cvec_model(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # instantiate estimator\n",
    "    svc = SVC()\n",
    "    \n",
    "    # instantiate vectorizer\n",
    "    cvec = CountVectorizer()\n",
    "    \n",
    "    # fit and transform features\n",
    "    cvec_train_data_features = cvec.fit_transform(X_train)\n",
    "    cvec_test_data_features = cvec.transform(X_test)\n",
    "    \n",
    "    # fit model\n",
    "    svc.fit(cvec_train_data_features, y_train)\n",
    "    \n",
    "    # print out accuracy scores\n",
    "    print(\"cvec support vector machine:\")\n",
    "    print(\"============================\")\n",
    "    print(f\"Train Score: {svc.score(cvec_train_data_features, y_train)}\")  \n",
    "    print(f\"Test Score: {svc.score(cvec_test_data_features, y_test)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_tvec_model(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # instantiate estimator\n",
    "    svc = SVC()\n",
    "    \n",
    "    # instantiate vectorizer\n",
    "    tvec = TfidfVectorizer()\n",
    "    \n",
    "    # fit and transform features\n",
    "    tvec_train_data_features = tvec.fit_transform(X_train)\n",
    "    tvec_test_data_features = tvec.transform(X_test)\n",
    "    \n",
    "    # fit model\n",
    "    svc.fit(tvec_train_data_features, y_train)\n",
    "    \n",
    "    # print out accuracy scores\n",
    "    print(\"tvec support vector machine:\")\n",
    "    print(\"============================\")\n",
    "    print(f\"Train Score: {svc.score(tvec_train_data_features, y_train)}\")  \n",
    "    print(f\"Test Score: {svc.score(tvec_test_data_features, y_test)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='results'></a>\n",
    "\n",
    "## Results\n",
    "\n",
    "---\n",
    "\n",
    "Using the above functions, all model results have been consolidated below for ease of comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='log-reg-results'></a>\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvec logistic regression model:\n",
      "===============================\n",
      "Best Score: 0.8941637542466664\n",
      "Best Parameters: {'cvec__max_features': None, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': None}\n",
      "\n",
      "Test Score: 0.8976055450535602\n"
     ]
    }
   ],
   "source": [
    "logreg_model(X_train, X_test, y_train, y_test, 'cvec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tvec logistic regression model:\n",
      "===============================\n",
      "Best Score: 0.8962643800737519\n",
      "Best Parameters: {'tvec__max_features': None, 'tvec__ngram_range': (1, 1), 'tvec__stop_words': 'english'}\n",
      "\n",
      "Test Score: 0.897500525099769\n"
     ]
    }
   ],
   "source": [
    "logreg_model(X_train, X_test, y_train, y_test, 'tvec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='naive-bayes-results'></a>\n",
    "\n",
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinomial naive bayes model:\n",
      "==============================\n",
      "Best Score: 0.9080629599993332\n",
      "Best Parameters: {'cvec__max_features': None, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': None}\n",
      "\n",
      "Test Score: 0.9081075404326822\n"
     ]
    }
   ],
   "source": [
    "mnb_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian naive bayes model:\n",
      "===========================\n",
      "Train Score: 0.8700416622903756\n",
      "Test Score: 0.7548834278512917\n"
     ]
    }
   ],
   "source": [
    "gnb_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='knn-results'></a>\n",
    "\n",
    "### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbors cvec model:\n",
      "===============================\n",
      "Best Score: 0.6657918436059879\n",
      "Best Parameters: {'n_neighbors': 5}\n",
      "\n",
      "Test Score: 0.6781138416299097\n"
     ]
    }
   ],
   "source": [
    "knn_cvec_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbors tvec model:\n",
      "===============================\n",
      "Best Score: 0.8140601304411138\n",
      "Best Parameters: {'n_neighbors': 25}\n",
      "\n",
      "Test Score: 0.7568788069733249\n"
     ]
    }
   ],
   "source": [
    "knn_tvec_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='random-forest-results'></a>\n",
    "\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest_cvec_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest_tvec_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='svm-results'></a>\n",
    "\n",
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvec support vector machine:\n",
      "============================\n",
      "Train Score: 0.9192311731960928\n",
      "Test Score: 0.8699852972064692\n"
     ]
    }
   ],
   "source": [
    "svm_cvec_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tvec support vector machine:\n",
      "============================\n",
      "Train Score: 0.9887616846969857\n",
      "Test Score: 0.9023314429741651\n"
     ]
    }
   ],
   "source": [
    "svm_tvec_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
